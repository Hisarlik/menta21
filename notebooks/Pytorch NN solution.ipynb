{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3534,
     "status": "ok",
     "timestamp": 1618040486978,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "B9cMjLN34v-5",
    "outputId": "d83277f0-deb9-45b9-c499-81e5efb0cb6c"
   },
   "outputs": [],
   "source": [
    "\n",
    "#!pip install wandb --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJDzt4YOtMy-"
   },
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5587,
     "status": "ok",
     "timestamp": 1618040489043,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "RZDb7klowQI-"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import wandb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5582,
     "status": "ok",
     "timestamp": 1618040489046,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "Lh1wPZ52rwRb"
   },
   "outputs": [],
   "source": [
    "# Deterministic\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(hash(\"setting random seeds\") % 2**28 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**28 - 1)\n",
    "torch.manual_seed(hash(\"by removing stochasticity\") % 2**28 - 1)\n",
    "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**28 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5575,
     "status": "ok",
     "timestamp": 1618040489046,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "hsmCoS9Ys_9F"
   },
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6452,
     "status": "ok",
     "timestamp": 1618040489930,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "xEInlYKG5H_o",
    "outputId": "1d4ec2de-b5fd-40a6-bdd4-e407b99d9aba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: antoniomenta (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wandb Login\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpfKCpu15IUV"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6444,
     "status": "ok",
     "timestamp": 1618040489931,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "dqdLjwGDunBb"
   },
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    epochs = 10,\n",
    "    batch_size = 80,\n",
    "    learning_rate = 0.001,\n",
    "    dataset = \"Authorship 2000\",\n",
    "    architecture = \"Dense:  Input, Layer 512, relu, batchnorm 512 , Layer 64, relu, batchnorm 64, dropout 0.1, output\", \n",
    "    criterion = \"BCEWithLogitsLoss\",\n",
    "    optimizer = \"Adam\"\n",
    "\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6437,
     "status": "ok",
     "timestamp": 1618040489931,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "WaLqbX-3j_r-"
   },
   "outputs": [],
   "source": [
    "class AuthorshipDataset(Dataset):\n",
    "\n",
    "  def __init__(self, X_ngrams_data, X_punct_data, y_data):\n",
    "    self.X_ngrams_data = X_ngrams_data\n",
    "    self.X_punct_data = X_punct_data\n",
    "    self.y_data = y_data\n",
    "\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    return self.X_ngrams_data[index], self.X_punct_data[index], self.y_data[index]\n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.y_data)\n",
    "\n",
    "  def vector_size(self):\n",
    "    return self.X_ngrams_data.shape[1], self.X_punct_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6430,
     "status": "ok",
     "timestamp": 1618040489932,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "_FO5tp3ooBS8"
   },
   "outputs": [],
   "source": [
    "class AuthorshipClassificationPunct(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size):\n",
    "    super(AuthorshipClassificationPunct, self).__init__()\n",
    " \n",
    "    print(\"input_size_punct:\",input_size[1])\n",
    "    self.layer1_punct = nn.Linear(input_size[1], 16)\n",
    "    self.layer2_punct = nn.Linear(16, 8)\n",
    "    self.output_layer = nn.Linear(8, 1)\n",
    "\n",
    "    self.relu = nn.ReLU()\n",
    "    self.dropout = nn.Dropout(p=0.1)\n",
    "    self.batchnorm1 = nn.BatchNorm1d(16)\n",
    "    self.batchnorm2 = nn.BatchNorm1d(8)\n",
    "\n",
    "  \n",
    "  def forward(self, inputs_ngrams, inputs_punct):\n",
    "\n",
    "    x_punct = self.layer1_punct(inputs_punct)\n",
    "    x_punct = self.relu(x_punct)\n",
    "    x_punct = self.batchnorm1(x_punct)\n",
    "    x_punct = self.layer2_punct(x_punct)\n",
    "    x_punct = self.relu(x_punct)\n",
    "    x_punct = self.batchnorm2(x_punct)\n",
    "    output = self.output_layer(x_punct)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 6424,
     "status": "ok",
     "timestamp": 1618040489933,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "oUwaH3HuloJh"
   },
   "outputs": [],
   "source": [
    "class AuthorshipClassificationNGrams(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size):\n",
    "    super(AuthorshipClassificationNGrams, self).__init__()\n",
    "\n",
    "    print(\"input_size_ngrams:\",input_size[0])\n",
    "    self.layer1_ngrams = nn.Linear(input_size[0], 128)\n",
    "    self.layer2_ngrams = nn.Linear(128, 32)\n",
    "    self.layer3_ngrams = nn.Linear(32, 16)\n",
    "    self.layer4_ngrams = nn.Linear(16, 4)\n",
    "    self.output_layer = nn.Linear(4, 1)\n",
    "\n",
    "    self.relu = nn.ReLU()\n",
    "    self.dropout = nn.Dropout(p=0.1)\n",
    "    self.batchnorm1 = nn.BatchNorm1d(128)\n",
    "    self.batchnorm2 = nn.BatchNorm1d(32)\n",
    "    self.batchnorm3 = nn.BatchNorm1d(16)\n",
    "    self.batchnorm4 = nn.BatchNorm1d(4)\n",
    "\n",
    "  \n",
    "  def forward(self, inputs_ngrams, inputs_punct):\n",
    "\n",
    "    x_grams = self.layer1_ngrams(inputs_ngrams)\n",
    "    x_grams = self.relu(x_grams)\n",
    "    x_grams = self.batchnorm1(x_grams)\n",
    "    #x_grams = self.dropout(x_grams)\n",
    "    x_grams = self.layer2_ngrams(x_grams)\n",
    "    x_grams = self.relu(x_grams)\n",
    "    #x_grams = self.batchnorm2(x_grams)\n",
    "    #x_grams = self.dropout(x_grams)\n",
    "    x_grams = self.layer3_ngrams(x_grams)\n",
    "    x_grams = self.relu(x_grams)\n",
    "    #x_grams = self.batchnorm3(x_grams)\n",
    "    #x_grams = self.dropout(x_grams)\n",
    "    x_grams = self.layer4_ngrams(x_grams)\n",
    "    x_grams = self.relu(x_grams)  \n",
    "    output = self.output_layer(x_grams)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 6417,
     "status": "ok",
     "timestamp": 1618040489933,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "Ds69uUqJkf6l"
   },
   "outputs": [],
   "source": [
    "class AuthorshipClassification(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size):\n",
    "    super(AuthorshipClassification, self).__init__()\n",
    "\n",
    "    print(\"input_size_ngrams:\",input_size[0])\n",
    "    self.layer1_ngrams = nn.Linear(input_size[0], 128)\n",
    "    self.layer2_ngrams = nn.Linear(128, 64)\n",
    "    self.layer3_ngrams = nn.Linear(64, 32)\n",
    "    self.layer4_ngrams = nn.Linear(32, 16)\n",
    "    self.layer5_ngrams = nn.Linear(16, 6)\n",
    " \n",
    "    print(\"input_size_punct:\",input_size[1])\n",
    "    self.layer1_punct = nn.Linear(input_size[1], 16)\n",
    "    self.layer2_punct = nn.Linear(16, 6)\n",
    "    #self.layer3_punct = nn.Linear(4, 2)\n",
    "\n",
    "    self.layer1_join = nn.Linear(12, 4)\n",
    "    self.layer2_join = nn.Linear(4, 2)\n",
    "    self.output_layer = nn.Linear(2, 1)\n",
    "\n",
    "    self.selu = nn.SELU()\n",
    "    self.dropout = nn.Dropout(p=0.1)\n",
    "    self.batchnorm1 = nn.BatchNorm1d(128)\n",
    "    #self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "    #self.batchnorm3 = nn.BatchNorm1d(32)\n",
    "    #self.batchnorm4 = nn.BatchNorm1d(16)\n",
    "\n",
    "  \n",
    "  def forward(self, inputs_ngrams, inputs_punct):\n",
    "\n",
    "    x_grams = self.layer1_ngrams(inputs_ngrams)\n",
    "    x_grams = self.selu(x_grams)\n",
    "    x_grams = self.batchnorm1(x_grams)\n",
    "    #x_grams = self.dropout(x_grams)\n",
    "    x_grams = self.layer2_ngrams(x_grams)\n",
    "    x_grams = self.selu(x_grams)\n",
    "    #x_grams = self.batchnorm2(x_grams)\n",
    "    #x_grams = self.dropout(x_grams)\n",
    "    x_grams = self.layer3_ngrams(x_grams)\n",
    "    x_grams = self.selu(x_grams)\n",
    "    #x_grams = self.batchnorm3(x_grams)\n",
    "    #x_grams = self.dropout(x_grams)\n",
    "    x_grams = self.layer4_ngrams(x_grams)\n",
    "    x_grams = self.selu(x_grams)  \n",
    "    #x_grams = self.batchnorm4(x_grams) \n",
    "    #x_grams = self.dropout(x_grams)  \n",
    "    x_grams = self.layer5_ngrams(x_grams)\n",
    "    x_grams = self.selu(x_grams)\n",
    "\n",
    "    x_punct = self.layer1_punct(inputs_punct)\n",
    "    x_punct = self.selu(x_punct)\n",
    "    x_punct = self.layer2_punct(x_punct)\n",
    "    x_punct = self.selu(x_punct)\n",
    "    #x_punct = self.relu(x_punct)\n",
    "    #x_punct = self.layer3_punct(x_punct)\n",
    "\n",
    "\n",
    "    x = torch.cat((x_grams, x_punct), dim=1)\n",
    "\n",
    "    x = self.layer1_join(x)\n",
    "    x = self.selu(x)\n",
    "    x = self.layer2_join(x)\n",
    "    x = self.selu(x)\n",
    "    output = self.output_layer(x)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 6410,
     "status": "ok",
     "timestamp": 1618040489934,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "51tXSoA4iMi2"
   },
   "outputs": [],
   "source": [
    "def model_pipeline(hyperparameters):\n",
    "\n",
    "  with wandb.init(project=\"authorship\", config=hyperparameters):\n",
    "\n",
    "    config = wandb.config\n",
    "    print(\"Calling make\")\n",
    "    model, train_loader, test_loader, criterion, optimizer = make(config)\n",
    "    print(model)\n",
    "\n",
    "    print(\"Calling train\")\n",
    "    train(model, train_loader, criterion, optimizer, config)\n",
    "\n",
    "    print(\"Calling test\")\n",
    "    return test(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 6403,
     "status": "ok",
     "timestamp": 1618040489934,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "Xmvgu28sbfd8"
   },
   "outputs": [],
   "source": [
    "def get_data(type_data=\"train\"):\n",
    "  TEMP_DATA_DIR = \"data/small/\"\n",
    "\n",
    "  if type_data == \"train\":\n",
    "    X_train_ngrams  = np.memmap(TEMP_DATA_DIR + 'features_ngrams_X_train.npy', dtype='float32', mode='r', shape=(35768, 44872))\n",
    "    X_train_punct = np.memmap(TEMP_DATA_DIR + 'features_punct_X_train.npy', dtype='float32', mode='r', shape=(35768, 32))\n",
    "    Y_train = np.memmap(TEMP_DATA_DIR + 'Y_train.npy', dtype='int32', mode='r', shape=(35768))\n",
    "    return AuthorshipDataset(torch.from_numpy(X_train_ngrams), \n",
    "                             torch.from_numpy(X_train_punct),\n",
    "                             torch.from_numpy(Y_train.astype('float32')))\n",
    "  elif type_data == \"test\":\n",
    "    X_test_ngrams = np.memmap(TEMP_DATA_DIR + 'features_ngrams_X_dev.npy', dtype='float32', mode='r', shape=(8942, 44872))\n",
    "    X_test_punct = np.memmap(TEMP_DATA_DIR + 'features_punct_X_dev.npy', dtype='float32', mode='r', shape=(8942, 32))\n",
    "    Y_test = np.memmap(TEMP_DATA_DIR + 'Y_dev.npy', dtype='int32', mode='r', shape=(8942))\n",
    "    return AuthorshipDataset(torch.from_numpy(X_test_ngrams), \n",
    "                             torch.from_numpy(X_test_punct),\n",
    "                             torch.from_numpy(Y_test.astype('float32')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Woyx58jzbwJM"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 6830,
     "status": "ok",
     "timestamp": 1618040490368,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "kPX9bQ5SjvgQ"
   },
   "outputs": [],
   "source": [
    "def make(config):\n",
    "\n",
    "  # get_data\n",
    "  data_train = get_data(type_data=\"train\")\n",
    "  data_test = get_data(type_data=\"test\")\n",
    "\n",
    "  data_input_size = data_train.vector_size()\n",
    "  \n",
    "  # data_loaders\n",
    "  train_loader = DataLoader(dataset=data_train, batch_size=config.batch_size, shuffle=False)\n",
    "  test_loader = DataLoader(dataset=data_test, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "  \n",
    "  #model\n",
    "  model = AuthorshipClassification(data_input_size).to(device)\n",
    "\n",
    "  # criterion and optimizer\n",
    "  criterion = nn.BCEWithLogitsLoss()\n",
    "  optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "\n",
    "  return model, train_loader, test_loader, criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 6824,
     "status": "ok",
     "timestamp": 1618040490369,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "4psUi1aws0Nk"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(y_pred, y_test):\n",
    "\n",
    "  y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "  correct_results = (y_pred_tag == y_test).sum().float()\n",
    "  acc = correct_results / y_test.shape[0]\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 6817,
     "status": "ok",
     "timestamp": 1618040490369,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "opRyUUWer0HC"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, config):\n",
    "\n",
    "  # Tell wandb to watch \n",
    "  wandb.watch(model, criterion, log_freq=10)\n",
    "\n",
    "  model.train()\n",
    "  for epoch in range(1, config.epochs+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_ngrams_batch, X_punct_batch, y_batch in train_loader:\n",
    "      X_ngrams_batch, X_punct_batch, y_batch = (X_ngrams_batch.to(device), \n",
    "                                                X_punct_batch.to(device), \n",
    "                                                y_batch.to(device))\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      y_pred = model(X_ngrams_batch, X_punct_batch)\n",
    "  \n",
    "\n",
    "      loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "      acc = binary_accuracy(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      epoch_loss += loss.item()\n",
    "      epoch_acc += acc.item()\n",
    "    print(f'Epoch {epoch}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')  \n",
    "    wandb.log({\n",
    "          \"Epoch\": epoch,\n",
    "          \"Train Accuracy\": epoch_acc/len(train_loader),\n",
    "          \"Train Loss\": epoch_loss/len(train_loader)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 6812,
     "status": "ok",
     "timestamp": 1618040490370,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "9chbla1dPjwd"
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    y_pred_list = []\n",
    "    # Run the model on some test examples\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        for X_ngrams_batch, X_punct_batch, y_batch in test_loader:\n",
    "            X_ngrams_batch,X_punct_batch ,y_batch = (X_ngrams_batch.to(device), \n",
    "                                                    X_punct_batch.to(device), \n",
    "                                                    y_batch.to(device))\n",
    "            outputs = model(X_ngrams_batch, X_punct_batch)\n",
    "            y_test_pred = torch.sigmoid(outputs)\n",
    "           \n",
    "            predicted = torch.round(y_test_pred).squeeze()\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "            print(f\"Accuracy of the model on the {total} \" +\n",
    "              f\"test data: {100 * correct / total}%\")\n",
    "\n",
    "\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.extend(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "        wandb.log({\"test_accuracy\": correct / total})\n",
    "\n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    torch.onnx.export(model,(X_ngrams_batch, X_punct_batch),\"model.onnx\")\n",
    "    #wandb.save(\"model.onnx\")\n",
    "    return y_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6805,
     "status": "ok",
     "timestamp": 1618040490370,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "wvGPrqSlwpUr",
    "outputId": "8280e3aa-dce3-4539-ea7a-c71841c68fad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start experiment\n"
     ]
    }
   ],
   "source": [
    "print(\"Start experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6800,
     "status": "ok",
     "timestamp": 1618040490373,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "rRkntfec6WQW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6794,
     "status": "ok",
     "timestamp": 1618040490374,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "JMHzw7G47keW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "id": "9OCcuyUCvF0-",
    "outputId": "f0d9c80b-e25c-4d1e-9e36-30a06854a23c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">icy-donkey-343</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/antoniomenta/authorship\" target=\"_blank\">https://wandb.ai/antoniomenta/authorship</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/antoniomenta/authorship/runs/29f6n7da\" target=\"_blank\">https://wandb.ai/antoniomenta/authorship/runs/29f6n7da</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\Antonio\\PhD\\Autoria\\Authorship-verification\\src\\wandb\\run-20210411_094958-29f6n7da</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling make\n",
      "input_size_ngrams: 44872\n",
      "input_size_punct: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-54d6c7107508>:8: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:143.)\n",
      "  return AuthorshipDataset(torch.from_numpy(X_train_ngrams),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AuthorshipClassification(\n",
      "  (layer1_ngrams): Linear(in_features=44872, out_features=128, bias=True)\n",
      "  (layer2_ngrams): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (layer3_ngrams): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (layer4_ngrams): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (layer5_ngrams): Linear(in_features=16, out_features=6, bias=True)\n",
      "  (layer1_punct): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (layer2_punct): Linear(in_features=16, out_features=6, bias=True)\n",
      "  (layer1_join): Linear(in_features=12, out_features=4, bias=True)\n",
      "  (layer2_join): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (output_layer): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (selu): SELU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "Calling train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antonio\\miniconda3\\envs\\authorship\\lib\\site-packages\\torch\\nn\\modules\\module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: | Loss: 0.35598 | Acc: 0.860\n",
      "Epoch 2: | Loss: 0.19543 | Acc: 0.925\n",
      "Epoch 3: | Loss: 0.12187 | Acc: 0.955\n",
      "Epoch 4: | Loss: 0.08341 | Acc: 0.969\n",
      "Epoch 5: | Loss: 0.06008 | Acc: 0.978\n",
      "Epoch 6: | Loss: 0.04523 | Acc: 0.984\n",
      "Epoch 7: | Loss: 0.03404 | Acc: 0.988\n",
      "Epoch 8: | Loss: 0.02676 | Acc: 0.990\n",
      "Epoch 9: | Loss: 0.02494 | Acc: 0.991\n",
      "Epoch 10: | Loss: 0.02176 | Acc: 0.992\n",
      "Calling test\n",
      "Accuracy of the model on the 80 test data: 92.5%\n",
      "Accuracy of the model on the 160 test data: 86.25%\n",
      "Accuracy of the model on the 240 test data: 87.91666666666667%\n",
      "Accuracy of the model on the 320 test data: 90.0%\n",
      "Accuracy of the model on the 400 test data: 89.5%\n",
      "Accuracy of the model on the 480 test data: 89.58333333333333%\n",
      "Accuracy of the model on the 560 test data: 89.10714285714286%\n",
      "Accuracy of the model on the 640 test data: 88.59375%\n",
      "Accuracy of the model on the 720 test data: 87.77777777777777%\n",
      "Accuracy of the model on the 800 test data: 88.25%\n",
      "Accuracy of the model on the 880 test data: 88.86363636363636%\n",
      "Accuracy of the model on the 960 test data: 88.54166666666667%\n",
      "Accuracy of the model on the 1040 test data: 88.9423076923077%\n",
      "Accuracy of the model on the 1120 test data: 88.75%\n",
      "Accuracy of the model on the 1200 test data: 88.66666666666667%\n",
      "Accuracy of the model on the 1280 test data: 89.0625%\n",
      "Accuracy of the model on the 1360 test data: 88.75%\n",
      "Accuracy of the model on the 1440 test data: 88.68055555555556%\n",
      "Accuracy of the model on the 1520 test data: 88.8157894736842%\n",
      "Accuracy of the model on the 1600 test data: 88.5625%\n",
      "Accuracy of the model on the 1680 test data: 88.80952380952381%\n",
      "Accuracy of the model on the 1760 test data: 88.63636363636364%\n",
      "Accuracy of the model on the 1840 test data: 88.6413043478261%\n",
      "Accuracy of the model on the 1920 test data: 88.75%\n",
      "Accuracy of the model on the 2000 test data: 88.7%\n",
      "Accuracy of the model on the 2080 test data: 88.65384615384616%\n",
      "Accuracy of the model on the 2160 test data: 88.70370370370371%\n",
      "Accuracy of the model on the 2240 test data: 88.75%\n",
      "Accuracy of the model on the 2320 test data: 89.00862068965517%\n",
      "Accuracy of the model on the 2400 test data: 89.04166666666667%\n",
      "Accuracy of the model on the 2480 test data: 89.0725806451613%\n",
      "Accuracy of the model on the 2560 test data: 88.9453125%\n",
      "Accuracy of the model on the 2640 test data: 88.86363636363636%\n",
      "Accuracy of the model on the 2720 test data: 88.8970588235294%\n",
      "Accuracy of the model on the 2800 test data: 88.92857142857143%\n",
      "Accuracy of the model on the 2880 test data: 88.95833333333333%\n",
      "Accuracy of the model on the 2960 test data: 88.88513513513513%\n",
      "Accuracy of the model on the 3040 test data: 88.88157894736842%\n",
      "Accuracy of the model on the 3120 test data: 88.87820512820512%\n",
      "Accuracy of the model on the 3200 test data: 88.90625%\n",
      "Accuracy of the model on the 3280 test data: 88.8719512195122%\n",
      "Accuracy of the model on the 3360 test data: 88.75%\n",
      "Accuracy of the model on the 3440 test data: 88.75%\n",
      "Accuracy of the model on the 3520 test data: 88.80681818181819%\n",
      "Accuracy of the model on the 3600 test data: 88.88888888888889%\n",
      "Accuracy of the model on the 3680 test data: 88.96739130434783%\n",
      "Accuracy of the model on the 3760 test data: 88.9627659574468%\n",
      "Accuracy of the model on the 3840 test data: 89.03645833333333%\n",
      "Accuracy of the model on the 3920 test data: 89.03061224489795%\n",
      "Accuracy of the model on the 4000 test data: 88.875%\n",
      "Accuracy of the model on the 4080 test data: 88.8970588235294%\n",
      "Accuracy of the model on the 4160 test data: 88.84615384615384%\n",
      "Accuracy of the model on the 4240 test data: 88.86792452830188%\n",
      "Accuracy of the model on the 4320 test data: 88.79629629629629%\n",
      "Accuracy of the model on the 4400 test data: 88.9090909090909%\n",
      "Accuracy of the model on the 4480 test data: 89.01785714285714%\n",
      "Accuracy of the model on the 4560 test data: 89.07894736842105%\n",
      "Accuracy of the model on the 4640 test data: 89.00862068965517%\n",
      "Accuracy of the model on the 4720 test data: 88.98305084745763%\n",
      "Accuracy of the model on the 4800 test data: 88.9375%\n",
      "Accuracy of the model on the 4880 test data: 88.89344262295081%\n",
      "Accuracy of the model on the 4960 test data: 88.8508064516129%\n",
      "Accuracy of the model on the 5040 test data: 88.86904761904762%\n",
      "Accuracy of the model on the 5120 test data: 88.9453125%\n",
      "Accuracy of the model on the 5200 test data: 88.9423076923077%\n",
      "Accuracy of the model on the 5280 test data: 88.92045454545455%\n",
      "Accuracy of the model on the 5360 test data: 89.01119402985074%\n",
      "Accuracy of the model on the 5440 test data: 89.02573529411765%\n",
      "Accuracy of the model on the 5520 test data: 89.07608695652173%\n",
      "Accuracy of the model on the 5600 test data: 89.07142857142857%\n",
      "Accuracy of the model on the 5680 test data: 89.03169014084507%\n",
      "Accuracy of the model on the 5760 test data: 88.97569444444444%\n",
      "Accuracy of the model on the 5840 test data: 89.02397260273973%\n",
      "Accuracy of the model on the 5920 test data: 89.02027027027027%\n",
      "Accuracy of the model on the 6000 test data: 89.01666666666667%\n",
      "Accuracy of the model on the 6080 test data: 89.07894736842105%\n",
      "Accuracy of the model on the 6160 test data: 89.12337662337663%\n",
      "Accuracy of the model on the 6240 test data: 89.1025641025641%\n",
      "Accuracy of the model on the 6320 test data: 89.03481012658227%\n",
      "Accuracy of the model on the 6400 test data: 88.984375%\n",
      "Accuracy of the model on the 6480 test data: 88.88888888888889%\n",
      "Accuracy of the model on the 6560 test data: 88.88719512195122%\n",
      "Accuracy of the model on the 6640 test data: 88.91566265060241%\n",
      "Accuracy of the model on the 6720 test data: 88.88392857142857%\n",
      "Accuracy of the model on the 6800 test data: 88.8970588235294%\n",
      "Accuracy of the model on the 6880 test data: 88.93895348837209%\n",
      "Accuracy of the model on the 6960 test data: 88.89367816091954%\n",
      "Accuracy of the model on the 7040 test data: 88.82102272727273%\n",
      "Accuracy of the model on the 7120 test data: 88.76404494382022%\n",
      "Accuracy of the model on the 7200 test data: 88.75%\n",
      "Accuracy of the model on the 7280 test data: 88.70879120879121%\n",
      "Accuracy of the model on the 7360 test data: 88.69565217391305%\n",
      "Accuracy of the model on the 7440 test data: 88.70967741935483%\n",
      "Accuracy of the model on the 7520 test data: 88.72340425531915%\n",
      "Accuracy of the model on the 7600 test data: 88.69736842105263%\n",
      "Accuracy of the model on the 7680 test data: 88.72395833333333%\n",
      "Accuracy of the model on the 7760 test data: 88.69845360824742%\n",
      "Accuracy of the model on the 7840 test data: 88.69897959183673%\n",
      "Accuracy of the model on the 7920 test data: 88.71212121212122%\n",
      "Accuracy of the model on the 8000 test data: 88.6625%\n",
      "Accuracy of the model on the 8080 test data: 88.61386138613861%\n",
      "Accuracy of the model on the 8160 test data: 88.63970588235294%\n",
      "Accuracy of the model on the 8240 test data: 88.68932038834951%\n",
      "Accuracy of the model on the 8320 test data: 88.6298076923077%\n",
      "Accuracy of the model on the 8400 test data: 88.66666666666667%\n",
      "Accuracy of the model on the 8480 test data: 88.64386792452831%\n",
      "Accuracy of the model on the 8560 test data: 88.57476635514018%\n",
      "Accuracy of the model on the 8640 test data: 88.59953703703704%\n",
      "Accuracy of the model on the 8720 test data: 88.60091743119266%\n",
      "Accuracy of the model on the 8800 test data: 88.60227272727273%\n",
      "Accuracy of the model on the 8880 test data: 88.6036036036036%\n",
      "Accuracy of the model on the 8942 test data: 88.62670543502573%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 17828<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\Antonio\\PhD\\Autoria\\Authorship-verification\\src\\wandb\\run-20210411_094958-29f6n7da\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\Antonio\\PhD\\Autoria\\Authorship-verification\\src\\wandb\\run-20210411_094958-29f6n7da\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.99208</td></tr><tr><td>Train Loss</td><td>0.02176</td></tr><tr><td>_runtime</td><td>102</td></tr><tr><td>_timestamp</td><td>1618127500</td></tr><tr><td>_step</td><td>10</td></tr><tr><td>test_accuracy</td><td>0.88627</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▃▂▂▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>_timestamp</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>_step</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">icy-donkey-343</strong>: <a href=\"https://wandb.ai/antoniomenta/authorship/runs/29f6n7da\" target=\"_blank\">https://wandb.ai/antoniomenta/authorship/runs/29f6n7da</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_list = model_pipeline(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "U7leP4uyKwU4"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'drive/MyDrive/Data/Autoria/small/Y_test.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-6105ec183239>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mTEMP_DATA_DIR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'drive/MyDrive/Data/Autoria/small/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTEMP_DATA_DIR\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'Y_test.npy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'int32'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8048\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\authorship\\lib\\site-packages\\numpy\\core\\memmap.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(subtype, filename, dtype, mode, offset, shape, order)\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[0mf_ctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontextlib_nullcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m             \u001b[0mf_ctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'r'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mf_ctx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive/Data/Autoria/small/Y_test.npy'"
     ]
    }
   ],
   "source": [
    "TEMP_DATA_DIR = 'drive/MyDrive/Data/Autoria/small/'\n",
    "Y_test = np.memmap(TEMP_DATA_DIR + 'Y_test.npy', dtype='int32', mode='r', shape=(8048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Suyaqaz-2gkH"
   },
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qNF2t_Z25DQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eGfjjsfT3CiE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN8eT3HvZDCtCCwgU5Z7lyS",
   "collapsed_sections": [],
   "mount_file_id": "1YAZAEcGUJjyu_LcbdaGk6DUc2QFZyyd7",
   "name": "Pytorch NN solution.ipynb",
   "provenance": [
    {
     "file_id": "1iSK6hX_rILEcomLvMbToUJh1pqJzO1NU",
     "timestamp": 1615806436527
    },
    {
     "file_id": "1V17SztQn9uXd2UYrIB3GTcl08o5zgb7N",
     "timestamp": 1615230463834
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
