{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3534,
     "status": "ok",
     "timestamp": 1618040486978,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "B9cMjLN34v-5",
    "outputId": "d83277f0-deb9-45b9-c499-81e5efb0cb6c"
   },
   "outputs": [],
   "source": [
    "\n",
    "#!pip install wandb --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJDzt4YOtMy-"
   },
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5587,
     "status": "ok",
     "timestamp": 1618040489043,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "RZDb7klowQI-"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import wandb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5582,
     "status": "ok",
     "timestamp": 1618040489046,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "Lh1wPZ52rwRb"
   },
   "outputs": [],
   "source": [
    "# Deterministic\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(hash(\"setting random seeds\") % 2**28 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**28 - 1)\n",
    "torch.manual_seed(hash(\"by removing stochasticity\") % 2**28 - 1)\n",
    "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**28 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5575,
     "status": "ok",
     "timestamp": 1618040489046,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "hsmCoS9Ys_9F"
   },
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6452,
     "status": "ok",
     "timestamp": 1618040489930,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "xEInlYKG5H_o",
    "outputId": "1d4ec2de-b5fd-40a6-bdd4-e407b99d9aba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: antoniomenta (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wandb Login\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpfKCpu15IUV"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6444,
     "status": "ok",
     "timestamp": 1618040489931,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "dqdLjwGDunBb"
   },
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    epochs = 10,\n",
    "    batch_size = 80,\n",
    "    learning_rate = 0.001,\n",
    "    dataset = \"Authorship 2000\",\n",
    "    architecture = \"Dense:  Input, Layer 512, relu, batchnorm 512 , Layer 64, relu, batchnorm 64, dropout 0.1, output\", \n",
    "    criterion = \"BCEWithLogitsLoss\",\n",
    "    optimizer = \"Adam\"\n",
    "\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6437,
     "status": "ok",
     "timestamp": 1618040489931,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "WaLqbX-3j_r-"
   },
   "outputs": [],
   "source": [
    "class AuthorshipDataset(Dataset):\n",
    "\n",
    "  def __init__(self, X_ngrams_data, X_punct_data, y_data):\n",
    "    self.X_ngrams_data = X_ngrams_data\n",
    "    self.X_punct_data = X_punct_data\n",
    "    self.y_data = y_data\n",
    "\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    return self.X_ngrams_data[index], self.X_punct_data[index], self.y_data[index]\n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.y_data)\n",
    "\n",
    "  def vector_size(self):\n",
    "    return self.X_ngrams_data.shape[1], self.X_punct_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6430,
     "status": "ok",
     "timestamp": 1618040489932,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "_FO5tp3ooBS8"
   },
   "outputs": [],
   "source": [
    "class AuthorshipClassificationPunct(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size):\n",
    "    super(AuthorshipClassificationPunct, self).__init__()\n",
    " \n",
    "    print(\"input_size_punct:\",input_size[1])\n",
    "    self.layer1_punct = nn.Linear(input_size[1], 16)\n",
    "    self.layer2_punct = nn.Linear(16, 8)\n",
    "    self.output_layer = nn.Linear(8, 1)\n",
    "\n",
    "    self.relu = nn.ReLU()\n",
    "    self.dropout = nn.Dropout(p=0.1)\n",
    "    self.batchnorm1 = nn.BatchNorm1d(16)\n",
    "    self.batchnorm2 = nn.BatchNorm1d(8)\n",
    "\n",
    "  \n",
    "  def forward(self, inputs_ngrams, inputs_punct):\n",
    "\n",
    "    x_punct = self.layer1_punct(inputs_punct)\n",
    "    x_punct = self.relu(x_punct)\n",
    "    x_punct = self.batchnorm1(x_punct)\n",
    "    x_punct = self.layer2_punct(x_punct)\n",
    "    x_punct = self.relu(x_punct)\n",
    "    x_punct = self.batchnorm2(x_punct)\n",
    "    output = self.output_layer(x_punct)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 6424,
     "status": "ok",
     "timestamp": 1618040489933,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "oUwaH3HuloJh"
   },
   "outputs": [],
   "source": [
    "class AuthorshipClassificationNGrams(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size):\n",
    "    super(AuthorshipClassificationNGrams, self).__init__()\n",
    "\n",
    "    print(\"input_size_ngrams:\",input_size[0])\n",
    "    self.layer1_ngrams = nn.Linear(input_size[0], 128)\n",
    "    self.layer2_ngrams = nn.Linear(128, 32)\n",
    "    self.layer3_ngrams = nn.Linear(32, 16)\n",
    "    self.layer4_ngrams = nn.Linear(16, 4)\n",
    "    self.output_layer = nn.Linear(4, 1)\n",
    "\n",
    "    self.relu = nn.ReLU()\n",
    "    self.dropout = nn.Dropout(p=0.1)\n",
    "    self.batchnorm1 = nn.BatchNorm1d(128)\n",
    "    self.batchnorm2 = nn.BatchNorm1d(32)\n",
    "    self.batchnorm3 = nn.BatchNorm1d(16)\n",
    "    self.batchnorm4 = nn.BatchNorm1d(4)\n",
    "\n",
    "  \n",
    "  def forward(self, inputs_ngrams, inputs_punct):\n",
    "\n",
    "    x_grams = self.layer1_ngrams(inputs_ngrams)\n",
    "    x_grams = self.relu(x_grams)\n",
    "    x_grams = self.batchnorm1(x_grams)\n",
    "    #x_grams = self.dropout(x_grams)\n",
    "    x_grams = self.layer2_ngrams(x_grams)\n",
    "    x_grams = self.relu(x_grams)\n",
    "    #x_grams = self.batchnorm2(x_grams)\n",
    "    #x_grams = self.dropout(x_grams)\n",
    "    x_grams = self.layer3_ngrams(x_grams)\n",
    "    x_grams = self.relu(x_grams)\n",
    "    #x_grams = self.batchnorm3(x_grams)\n",
    "    #x_grams = self.dropout(x_grams)\n",
    "    x_grams = self.layer4_ngrams(x_grams)\n",
    "    x_grams = self.relu(x_grams)  \n",
    "    output = self.output_layer(x_grams)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 6417,
     "status": "ok",
     "timestamp": 1618040489933,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "Ds69uUqJkf6l"
   },
   "outputs": [],
   "source": [
    "class AuthorshipClassification(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size):\n",
    "    super(AuthorshipClassification, self).__init__()\n",
    "\n",
    "    print(\"input_size_ngrams:\",input_size[0])\n",
    "    self.layer1_ngrams = nn.Linear(input_size[0], 128)\n",
    "    self.layer2_ngrams = nn.Linear(128, 64)\n",
    "    self.layer3_ngrams = nn.Linear(64, 32)\n",
    "    self.layer4_ngrams = nn.Linear(32, 16)\n",
    "    self.layer5_ngrams = nn.Linear(16, 6)\n",
    " \n",
    "    print(\"input_size_punct:\",input_size[1])\n",
    "    self.layer1_punct = nn.Linear(input_size[1], 16)\n",
    "    self.layer2_punct = nn.Linear(16, 6)\n",
    "    #self.layer3_punct = nn.Linear(4, 2)\n",
    "\n",
    "    self.layer1_join = nn.Linear(12, 4)\n",
    "    self.layer2_join = nn.Linear(4, 2)\n",
    "    self.output_layer = nn.Linear(2, 1)\n",
    "\n",
    "    self.selu = nn.SELU()\n",
    "    self.dropout = nn.Dropout(p=0.1)\n",
    "    self.batchnorm1 = nn.BatchNorm1d(128)\n",
    "    #self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "    #self.batchnorm3 = nn.BatchNorm1d(32)\n",
    "    #self.batchnorm4 = nn.BatchNorm1d(16)\n",
    "\n",
    "  \n",
    "  def forward(self, inputs_ngrams, inputs_punct):\n",
    "\n",
    "    x_grams = self.layer1_ngrams(inputs_ngrams)\n",
    "    x_grams = self.selu(x_grams)\n",
    "    x_grams = self.batchnorm1(x_grams)\n",
    "    #x_grams = self.dropout(x_grams)\n",
    "    x_grams = self.layer2_ngrams(x_grams)\n",
    "    x_grams = self.selu(x_grams)\n",
    "    #x_grams = self.batchnorm2(x_grams)\n",
    "    #x_grams = self.dropout(x_grams)\n",
    "    x_grams = self.layer3_ngrams(x_grams)\n",
    "    x_grams = self.selu(x_grams)\n",
    "    #x_grams = self.batchnorm3(x_grams)\n",
    "    #x_grams = self.dropout(x_grams)\n",
    "    x_grams = self.layer4_ngrams(x_grams)\n",
    "    x_grams = self.selu(x_grams)  \n",
    "    #x_grams = self.batchnorm4(x_grams) \n",
    "    #x_grams = self.dropout(x_grams)  \n",
    "    x_grams = self.layer5_ngrams(x_grams)\n",
    "    x_grams = self.selu(x_grams)\n",
    "\n",
    "    x_punct = self.layer1_punct(inputs_punct)\n",
    "    x_punct = self.selu(x_punct)\n",
    "    x_punct = self.layer2_punct(x_punct)\n",
    "    x_punct = self.selu(x_punct)\n",
    "    #x_punct = self.relu(x_punct)\n",
    "    #x_punct = self.layer3_punct(x_punct)\n",
    "\n",
    "\n",
    "    x = torch.cat((x_grams, x_punct), dim=1)\n",
    "\n",
    "    x = self.layer1_join(x)\n",
    "    x = self.selu(x)\n",
    "    x = self.layer2_join(x)\n",
    "    x = self.selu(x)\n",
    "    output = self.output_layer(x)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 6410,
     "status": "ok",
     "timestamp": 1618040489934,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "51tXSoA4iMi2"
   },
   "outputs": [],
   "source": [
    "def model_pipeline(hyperparameters):\n",
    "\n",
    "  with wandb.init(project=\"authorship\", config=hyperparameters):\n",
    "\n",
    "    config = wandb.config\n",
    "    print(\"Calling make\")\n",
    "    model, train_loader, test_loader, criterion, optimizer = make(config)\n",
    "    print(model)\n",
    "\n",
    "    print(\"Calling train\")\n",
    "    train(model, train_loader, criterion, optimizer, config)\n",
    "\n",
    "    print(\"Calling test\")\n",
    "    return test(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 6403,
     "status": "ok",
     "timestamp": 1618040489934,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "Xmvgu28sbfd8"
   },
   "outputs": [],
   "source": [
    "def get_data(type_data=\"train\"):\n",
    "  TEMP_DATA_DIR = \"../data/small/\"\n",
    "\n",
    "  if type_data == \"train\":\n",
    "    X_train_ngrams  = np.memmap(TEMP_DATA_DIR + 'features_ngrams_X_train.npy', dtype='float32', mode='r', shape=(35768, 44872))\n",
    "    X_train_punct = np.memmap(TEMP_DATA_DIR + 'features_punct_X_train.npy', dtype='float32', mode='r', shape=(35768, 32))\n",
    "    Y_train = np.memmap(TEMP_DATA_DIR + 'Y_train.npy', dtype='int32', mode='r', shape=(35768))\n",
    "    return AuthorshipDataset(torch.from_numpy(X_train_ngrams), \n",
    "                             torch.from_numpy(X_train_punct),\n",
    "                             torch.from_numpy(Y_train.astype('float32')))\n",
    "  elif type_data == \"test\":\n",
    "    X_test_ngrams = np.memmap(TEMP_DATA_DIR + 'features_ngrams_X_dev.npy', dtype='float32', mode='r', shape=(8942, 44872))\n",
    "    X_test_punct = np.memmap(TEMP_DATA_DIR + 'features_punct_X_dev.npy', dtype='float32', mode='r', shape=(8942, 32))\n",
    "    Y_test = np.memmap(TEMP_DATA_DIR + 'Y_dev.npy', dtype='int32', mode='r', shape=(8942))\n",
    "    return AuthorshipDataset(torch.from_numpy(X_test_ngrams), \n",
    "                             torch.from_numpy(X_test_punct),\n",
    "                             torch.from_numpy(Y_test.astype('float32')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Woyx58jzbwJM"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 6830,
     "status": "ok",
     "timestamp": 1618040490368,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "kPX9bQ5SjvgQ"
   },
   "outputs": [],
   "source": [
    "def make(config):\n",
    "\n",
    "  # get_data\n",
    "  data_train = get_data(type_data=\"train\")\n",
    "  data_test = get_data(type_data=\"test\")\n",
    "\n",
    "  data_input_size = data_train.vector_size()\n",
    "  \n",
    "  # data_loaders\n",
    "  train_loader = DataLoader(dataset=data_train, batch_size=config.batch_size, shuffle=False)\n",
    "  test_loader = DataLoader(dataset=data_test, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "  \n",
    "  #model\n",
    "  model = AuthorshipClassification(data_input_size).to(device)\n",
    "\n",
    "  # criterion and optimizer\n",
    "  criterion = nn.BCEWithLogitsLoss()\n",
    "  optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "\n",
    "  return model, train_loader, test_loader, criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 6824,
     "status": "ok",
     "timestamp": 1618040490369,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "4psUi1aws0Nk"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(y_pred, y_test):\n",
    "\n",
    "  y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "  correct_results = (y_pred_tag == y_test).sum().float()\n",
    "  acc = correct_results / y_test.shape[0]\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 6817,
     "status": "ok",
     "timestamp": 1618040490369,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "opRyUUWer0HC"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, config):\n",
    "\n",
    "  # Tell wandb to watch \n",
    "  wandb.watch(model, criterion, log_freq=10)\n",
    "\n",
    "  model.train()\n",
    "  for epoch in range(1, config.epochs+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_ngrams_batch, X_punct_batch, y_batch in train_loader:\n",
    "      X_ngrams_batch, X_punct_batch, y_batch = (X_ngrams_batch.to(device), \n",
    "                                                X_punct_batch.to(device), \n",
    "                                                y_batch.to(device))\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      y_pred = model(X_ngrams_batch, X_punct_batch)\n",
    "  \n",
    "\n",
    "      loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "      acc = binary_accuracy(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      epoch_loss += loss.item()\n",
    "      epoch_acc += acc.item()\n",
    "    print(f'Epoch {epoch}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')  \n",
    "    wandb.log({\n",
    "          \"Epoch\": epoch,\n",
    "          \"Train Accuracy\": epoch_acc/len(train_loader),\n",
    "          \"Train Loss\": epoch_loss/len(train_loader)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 6812,
     "status": "ok",
     "timestamp": 1618040490370,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "9chbla1dPjwd"
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    y_pred_list = []\n",
    "    # Run the model on some test examples\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        for X_ngrams_batch, X_punct_batch, y_batch in test_loader:\n",
    "            X_ngrams_batch,X_punct_batch ,y_batch = (X_ngrams_batch.to(device), \n",
    "                                                    X_punct_batch.to(device), \n",
    "                                                    y_batch.to(device))\n",
    "            outputs = model(X_ngrams_batch, X_punct_batch)\n",
    "            y_test_pred = torch.sigmoid(outputs)\n",
    "           \n",
    "            predicted = torch.round(y_test_pred).squeeze()\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "            print(f\"Accuracy of the model on the {total} \" +\n",
    "              f\"test data: {100 * correct / total}%\")\n",
    "\n",
    "\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.extend(y_pred_tag.cpu().numpy())\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "        wandb.log({\"test_accuracy\": correct / total})\n",
    "\n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    torch.onnx.export(model,(X_ngrams_batch, X_punct_batch),\"model.onnx\")\n",
    "    #wandb.save(\"model.onnx\")\n",
    "    return y_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6805,
     "status": "ok",
     "timestamp": 1618040490370,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "wvGPrqSlwpUr",
    "outputId": "8280e3aa-dce3-4539-ea7a-c71841c68fad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start experiment\n"
     ]
    }
   ],
   "source": [
    "print(\"Start experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6800,
     "status": "ok",
     "timestamp": 1618040490373,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "rRkntfec6WQW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6794,
     "status": "ok",
     "timestamp": 1618040490374,
     "user": {
      "displayName": "Antonio Menta",
      "photoUrl": "",
      "userId": "05293560215470938561"
     },
     "user_tz": -120
    },
    "id": "JMHzw7G47keW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "id": "9OCcuyUCvF0-",
    "outputId": "f0d9c80b-e25c-4d1e-9e36-30a06854a23c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">wild-breeze-344</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/antoniomenta/authorship\" target=\"_blank\">https://wandb.ai/antoniomenta/authorship</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/antoniomenta/authorship/runs/3jlkin66\" target=\"_blank\">https://wandb.ai/antoniomenta/authorship/runs/3jlkin66</a><br/>\n",
       "                Run data is saved locally in <code>c:\\Users\\Antonio\\PhD\\Autoria\\Authorship-verification\\notebooks\\wandb\\run-20210411_111835-3jlkin66</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling make\n",
      "input_size_ngrams: 44872\n",
      "input_size_punct: 32\n",
      "<ipython-input-12-dfc744cae0b0>:8: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:143.)\n",
      "  return AuthorshipDataset(torch.from_numpy(X_train_ngrams),\n",
      "AuthorshipClassification(\n",
      "  (layer1_ngrams): Linear(in_features=44872, out_features=128, bias=True)\n",
      "  (layer2_ngrams): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (layer3_ngrams): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (layer4_ngrams): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (layer5_ngrams): Linear(in_features=16, out_features=6, bias=True)\n",
      "  (layer1_punct): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (layer2_punct): Linear(in_features=16, out_features=6, bias=True)\n",
      "  (layer1_join): Linear(in_features=12, out_features=4, bias=True)\n",
      "  (layer2_join): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (output_layer): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (selu): SELU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "Calling train\n",
      "C:\\Users\\Antonio\\miniconda3\\envs\\authorship\\lib\\site-packages\\torch\\nn\\modules\\module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "Epoch 1: | Loss: 0.35593 | Acc: 0.856\n",
      "Epoch 2: | Loss: 0.20089 | Acc: 0.921\n",
      "Epoch 3: | Loss: 0.13533 | Acc: 0.947\n",
      "Epoch 4: | Loss: 0.09330 | Acc: 0.964\n",
      "Epoch 5: | Loss: 0.06287 | Acc: 0.975\n",
      "Epoch 6: | Loss: 0.04698 | Acc: 0.982\n",
      "Epoch 7: | Loss: 0.03715 | Acc: 0.986\n",
      "Epoch 8: | Loss: 0.03110 | Acc: 0.989\n",
      "Epoch 9: | Loss: 0.02533 | Acc: 0.991\n",
      "Epoch 10: | Loss: 0.02435 | Acc: 0.992\n",
      "Calling test\n",
      "Accuracy of the model on the 80 test data: 91.25%\n",
      "Accuracy of the model on the 160 test data: 90.625%\n",
      "Accuracy of the model on the 240 test data: 89.58333333333333%\n",
      "Accuracy of the model on the 320 test data: 89.6875%\n",
      "Accuracy of the model on the 400 test data: 90.0%\n",
      "Accuracy of the model on the 480 test data: 89.58333333333333%\n",
      "Accuracy of the model on the 560 test data: 89.64285714285714%\n",
      "Accuracy of the model on the 640 test data: 89.375%\n",
      "Accuracy of the model on the 720 test data: 89.02777777777777%\n",
      "Accuracy of the model on the 800 test data: 89.375%\n",
      "Accuracy of the model on the 880 test data: 89.6590909090909%\n",
      "Accuracy of the model on the 960 test data: 89.6875%\n",
      "Accuracy of the model on the 1040 test data: 89.71153846153847%\n",
      "Accuracy of the model on the 1120 test data: 89.82142857142857%\n",
      "Accuracy of the model on the 1200 test data: 89.91666666666667%\n",
      "Accuracy of the model on the 1280 test data: 90.078125%\n",
      "Accuracy of the model on the 1360 test data: 89.92647058823529%\n",
      "Accuracy of the model on the 1440 test data: 89.86111111111111%\n",
      "Accuracy of the model on the 1520 test data: 89.86842105263158%\n",
      "Accuracy of the model on the 1600 test data: 89.6875%\n",
      "Accuracy of the model on the 1680 test data: 89.88095238095238%\n",
      "Accuracy of the model on the 1760 test data: 89.6590909090909%\n",
      "Accuracy of the model on the 1840 test data: 89.94565217391305%\n",
      "Accuracy of the model on the 1920 test data: 90.15625%\n",
      "Accuracy of the model on the 2000 test data: 90.1%\n",
      "Accuracy of the model on the 2080 test data: 90.09615384615384%\n",
      "Accuracy of the model on the 2160 test data: 90.0%\n",
      "Accuracy of the model on the 2240 test data: 89.91071428571429%\n",
      "Accuracy of the model on the 2320 test data: 89.95689655172414%\n",
      "Accuracy of the model on the 2400 test data: 89.875%\n",
      "Accuracy of the model on the 2480 test data: 89.83870967741936%\n",
      "Accuracy of the model on the 2560 test data: 89.84375%\n",
      "Accuracy of the model on the 2640 test data: 89.6969696969697%\n",
      "Accuracy of the model on the 2720 test data: 89.74264705882354%\n",
      "Accuracy of the model on the 2800 test data: 89.75%\n",
      "Accuracy of the model on the 2880 test data: 89.89583333333333%\n",
      "Accuracy of the model on the 2960 test data: 89.76351351351352%\n",
      "Accuracy of the model on the 3040 test data: 89.86842105263158%\n",
      "Accuracy of the model on the 3120 test data: 89.77564102564102%\n",
      "Accuracy of the model on the 3200 test data: 89.8125%\n",
      "Accuracy of the model on the 3280 test data: 89.7560975609756%\n",
      "Accuracy of the model on the 3360 test data: 89.79166666666667%\n",
      "Accuracy of the model on the 3440 test data: 89.8546511627907%\n",
      "Accuracy of the model on the 3520 test data: 89.91477272727273%\n",
      "Accuracy of the model on the 3600 test data: 89.94444444444444%\n",
      "Accuracy of the model on the 3680 test data: 89.97282608695652%\n",
      "Accuracy of the model on the 3760 test data: 89.97340425531915%\n",
      "Accuracy of the model on the 3840 test data: 90.02604166666667%\n",
      "Accuracy of the model on the 3920 test data: 90.02551020408163%\n",
      "Accuracy of the model on the 4000 test data: 89.925%\n",
      "Accuracy of the model on the 4080 test data: 89.90196078431373%\n",
      "Accuracy of the model on the 4160 test data: 89.92788461538461%\n",
      "Accuracy of the model on the 4240 test data: 89.97641509433963%\n",
      "Accuracy of the model on the 4320 test data: 89.88425925925925%\n",
      "Accuracy of the model on the 4400 test data: 89.88636363636364%\n",
      "Accuracy of the model on the 4480 test data: 89.91071428571429%\n",
      "Accuracy of the model on the 4560 test data: 90.0%\n",
      "Accuracy of the model on the 4640 test data: 89.97844827586206%\n",
      "Accuracy of the model on the 4720 test data: 89.97881355932203%\n",
      "Accuracy of the model on the 4800 test data: 89.97916666666667%\n",
      "Accuracy of the model on the 4880 test data: 89.95901639344262%\n",
      "Accuracy of the model on the 4960 test data: 89.8991935483871%\n",
      "Accuracy of the model on the 5040 test data: 89.96031746031746%\n",
      "Accuracy of the model on the 5120 test data: 90.05859375%\n",
      "Accuracy of the model on the 5200 test data: 90.0576923076923%\n",
      "Accuracy of the model on the 5280 test data: 90.05681818181819%\n",
      "Accuracy of the model on the 5360 test data: 90.11194029850746%\n",
      "Accuracy of the model on the 5440 test data: 90.07352941176471%\n",
      "Accuracy of the model on the 5520 test data: 90.07246376811594%\n",
      "Accuracy of the model on the 5600 test data: 90.01785714285714%\n",
      "Accuracy of the model on the 5680 test data: 89.94718309859155%\n",
      "Accuracy of the model on the 5760 test data: 89.91319444444444%\n",
      "Accuracy of the model on the 5840 test data: 89.9486301369863%\n",
      "Accuracy of the model on the 5920 test data: 89.98310810810811%\n",
      "Accuracy of the model on the 6000 test data: 89.93333333333334%\n",
      "Accuracy of the model on the 6080 test data: 90.01644736842105%\n",
      "Accuracy of the model on the 6160 test data: 90.0487012987013%\n",
      "Accuracy of the model on the 6240 test data: 90.01602564102564%\n",
      "Accuracy of the model on the 6320 test data: 89.95253164556962%\n",
      "Accuracy of the model on the 6400 test data: 89.953125%\n",
      "Accuracy of the model on the 6480 test data: 89.89197530864197%\n",
      "Accuracy of the model on the 6560 test data: 89.84756097560975%\n",
      "Accuracy of the model on the 6640 test data: 89.81927710843374%\n",
      "Accuracy of the model on the 6720 test data: 89.79166666666667%\n",
      "Accuracy of the model on the 6800 test data: 89.79411764705883%\n",
      "Accuracy of the model on the 6880 test data: 89.79651162790698%\n",
      "Accuracy of the model on the 6960 test data: 89.75574712643679%\n",
      "Accuracy of the model on the 7040 test data: 89.7159090909091%\n",
      "Accuracy of the model on the 7120 test data: 89.69101123595506%\n",
      "Accuracy of the model on the 7200 test data: 89.66666666666667%\n",
      "Accuracy of the model on the 7280 test data: 89.67032967032966%\n",
      "Accuracy of the model on the 7360 test data: 89.6195652173913%\n",
      "Accuracy of the model on the 7440 test data: 89.65053763440861%\n",
      "Accuracy of the model on the 7520 test data: 89.64095744680851%\n",
      "Accuracy of the model on the 7600 test data: 89.60526315789474%\n",
      "Accuracy of the model on the 7680 test data: 89.6484375%\n",
      "Accuracy of the model on the 7760 test data: 89.63917525773196%\n",
      "Accuracy of the model on the 7840 test data: 89.63010204081633%\n",
      "Accuracy of the model on the 7920 test data: 89.5959595959596%\n",
      "Accuracy of the model on the 8000 test data: 89.575%\n",
      "Accuracy of the model on the 8080 test data: 89.5049504950495%\n",
      "Accuracy of the model on the 8160 test data: 89.49754901960785%\n",
      "Accuracy of the model on the 8240 test data: 89.52669902912622%\n",
      "Accuracy of the model on the 8320 test data: 89.44711538461539%\n",
      "Accuracy of the model on the 8400 test data: 89.4047619047619%\n",
      "Accuracy of the model on the 8480 test data: 89.42216981132076%\n",
      "Accuracy of the model on the 8560 test data: 89.41588785046729%\n",
      "Accuracy of the model on the 8640 test data: 89.42129629629629%\n",
      "Accuracy of the model on the 8720 test data: 89.44954128440367%\n",
      "Accuracy of the model on the 8800 test data: 89.45454545454545%\n",
      "Accuracy of the model on the 8880 test data: 89.48198198198199%\n",
      "Accuracy of the model on the 8942 test data: 89.47662715276225%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 17412<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e85ee8e2a34295b8fc2ac3f78f7ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>c:\\Users\\Antonio\\PhD\\Autoria\\Authorship-verification\\notebooks\\wandb\\run-20210411_111835-3jlkin66\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>c:\\Users\\Antonio\\PhD\\Autoria\\Authorship-verification\\notebooks\\wandb\\run-20210411_111835-3jlkin66\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.99185</td></tr><tr><td>Train Loss</td><td>0.02435</td></tr><tr><td>_runtime</td><td>147</td></tr><tr><td>_timestamp</td><td>1618132862</td></tr><tr><td>_step</td><td>10</td></tr><tr><td>test_accuracy</td><td>0.89477</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▆▇▇█████</td></tr><tr><td>Train Loss</td><td>█▅▃▂▂▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>_timestamp</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>_step</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>test_accuracy</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">wild-breeze-344</strong>: <a href=\"https://wandb.ai/antoniomenta/authorship/runs/3jlkin66\" target=\"_blank\">https://wandb.ai/antoniomenta/authorship/runs/3jlkin66</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_list = model_pipeline(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "U7leP4uyKwU4"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 8] No hay suficientes recursos de memoria disponibles para procesar este comando",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-3e594fca9914>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mTEMP_DATA_DIR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../data/small/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTEMP_DATA_DIR\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'Y_test.npy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'int32'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8048\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\authorship\\lib\\site-packages\\numpy\\core\\memmap.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(subtype, filename, dtype, mode, offset, shape, order)\u001b[0m\n\u001b[0;32m    262\u001b[0m             \u001b[0mbytes\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[0marray_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moffset\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m             \u001b[0mmm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmmap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccess\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m             self = ndarray.__new__(subtype, shape, dtype=descr, buffer=mm,\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 8] No hay suficientes recursos de memoria disponibles para procesar este comando"
     ]
    }
   ],
   "source": [
    "TEMP_DATA_DIR = '../data/small/'\n",
    "Y_test = np.memmap(TEMP_DATA_DIR + 'Y_test.npy', dtype='int32', mode='r', shape=(8048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Suyaqaz-2gkH"
   },
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qNF2t_Z25DQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eGfjjsfT3CiE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN8eT3HvZDCtCCwgU5Z7lyS",
   "collapsed_sections": [],
   "mount_file_id": "1YAZAEcGUJjyu_LcbdaGk6DUc2QFZyyd7",
   "name": "Pytorch NN solution.ipynb",
   "provenance": [
    {
     "file_id": "1iSK6hX_rILEcomLvMbToUJh1pqJzO1NU",
     "timestamp": 1615806436527
    },
    {
     "file_id": "1V17SztQn9uXd2UYrIB3GTcl08o5zgb7N",
     "timestamp": 1615230463834
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
